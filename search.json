[
  {
    "objectID": "src/key-takeaway.html",
    "href": "src/key-takeaway.html",
    "title": "Key Takeaways",
    "section": "",
    "text": "Best Practices\n(Capture the main takeaways and results of the project)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Prompting Guide",
    "section": "",
    "text": "SL",
    "crumbs": [
      "Prompting Guide"
    ]
  },
  {
    "objectID": "index.html#ibm-watsonx-code-assistant-prompting-guide-practical-hands-on",
    "href": "index.html#ibm-watsonx-code-assistant-prompting-guide-practical-hands-on",
    "title": "Prompting Guide",
    "section": "IBM watsonx Code Assistant Prompting Guide: Practical hands-on",
    "text": "IBM watsonx Code Assistant Prompting Guide: Practical hands-on\n\n‚ñ∂Ô∏è A code editor extension that captures and transmits prompt and context information for inference and captures feed-back from the user to improve model and service quality.\n‚ñ∂Ô∏è An inference pipeline for combining and processing natural language and code to get code suggestions from a Large Language Models (LLMs).\n‚ñ∂Ô∏è A content matching pipeline that finds training examples that are similar to the code suggestions.\n‚ñ∂Ô∏è An analysis framework that collects and processes feedback data to make it consumable by a wide range of analysis tools, ultimately for the purpose of improving model quality and user experience.\nOne of the key advantages of watsonx Code Assistant is its ability to leverage context and industry best practices to generate intelligent suggestions. As you use watsonx Code Assistant, you‚Äôll notice that it incorporates context from the overall source file and the specific paragraph to provide more accurate recommendations. It analyzes the code you have already written and suggests improvements or additions based on established best practices.",
    "crumbs": [
      "Prompting Guide"
    ]
  },
  {
    "objectID": "index.html#here-are-a-few-key-examples-of-simple-ways-to-enhance-your-experience",
    "href": "index.html#here-are-a-few-key-examples-of-simple-ways-to-enhance-your-experience",
    "title": "Prompting Guide",
    "section": "Here are a few key examples of simple ways to enhance your experienceüëá",
    "text": "Here are a few key examples of simple ways to enhance your experienceüëá\n\nUse personas or role names to provide context\nThe LLM supporting watsonx Code Assistant is tuned to support 116 different programming languages. When prompting for content, explanations, or opportunities for improvement, it‚Äôs important to provide context that includes the role or persona that would otherwise be expected to produce the content without AI.\nLet‚Äôs start with a basic query for language recommendations. Suppose you work for an operational technology company that produces embedded systems, sensors, and other instruments. You want to implement the UNIX cat command and ask the following question:\nGood: Between C, C++, and Ada, which language is best for implementing the UNIX \"cat\" command?\nThis is a good start, and one improvement would be to prepend a sentence that provides more context. Consider the following:\nBetter: You are an embedded systems programmer. Between C, C++, and Ada, which language is best for implementing the UNIX \"cat\" command?\nThis is better because the needed skillset is now much clearer. Finally, it would help to include any specific requirements. For example:\nBest: You are an embedded systems programmer building secure fielded instruments. Between C, C++, and Ada, which language is best for implementing the UNIX \"cat\" command?\nThis is better than Better because the prompt makes visible the security needs, thus avoiding a follow up prompt such as, What if I need robust security capabilities?\n\n\n\nAvoid ‚Äúgive me a rock / no, not that rock‚Äù by starting with specific details, to reduce iterations\nRemember when you first learned how to code? Perhaps your instructor said that computers will do exactly what you tell them to do. LLMs aren‚Äôt very different in that regard, so take the time to add important details to your prompts. For example:\nGood: You are an Ansible engineer. Write a playbook that deploys IBM MQ on OpenShift.\nThis is also a good start, but you might get content that supports older versions of OpenShift like OCP 3. If you need OpenShift 4 support, modify your prompt by adding a ‚Äú4‚Äù at the end.\nBetter: You are an Ansible engineer. Write a playbook that deploys IBM MQ on OpenShift 4.\nThis is more specific, but then you notice the proposed content suggests passing OpenShift CLI commands instead of using a bespoke Ansible module, which may not be idempotent. Further, the proposed content uses short module names which is a linting violation; and you remember that, in OpenShift, services are not exposed as routes by default.\nBest: You are an Ansible engineer. Write a playbook that deploys IBM MQ on OpenShift 4 with an exposed route. Use the kubernetes.core collection. Use fully qualified collection names.\nBy being more specific, you can generate more useful code and spend less time correcting. The good news here is that watsonx Code Assistant retains context in each chat, which means you can propose corrections conversationally instead of having to rewrite the entire prompt.\n\n\nParameterize Parameterize Parameterize\nIf you use hard-coded information in your prompt, there‚Äôs an excellent chance the response will be anonymized or otherwise different from what you prompted. For example, if you prompt with:\nYou are a Cisco NXOS engineer. Write a script that sets the secondary interface IPv4 address for Ethernet1/2 to 194.99.2.254/24.\nYou might get a response that uses a different number in the fourth octet of the IPv4 address, or a different IPv4 address entirely. Consider this improvement:\nYou are a Cisco NXOS engineer. Write a script that sets the secondary interface IPv4 address for a parameterized layer 1 interface name to a parameterized IPv4 address formatted as CIDR.\nYou could even give an example:\nYou are a Cisco NXOS engineer. Write a script that sets the secondary interface IPv4 address for a parameterized layer 1 interface name like \"Ethernet1/2\" to a parameterized IPv4 address formatted as CIDR like \"192.168.1.200/24.\"\nExperiment with different approaches, but remember that the use of hard-coded data is an anti-pattern.\n\n\nGenerating API version specific code.\nWhen working with certain APIs such as Azure API, the code will use an API with a specific version date:\nThe Prompt:\nWrite a bicep to create a keyvault\nThe code output generated by WCA includes the following dated Azure API version:\n...\nresource keyVault 'Microsoft.KeyVault/vaults@2019-09-01' = {\n  name: keyVaultName\nBut is that the newest API version available in the training data? We can ask the model:\nList only the dates of the KeyVault Azure API available to you.\nWe receive the following output:\nHere are the dates for the available Key Vault API versions as of April 2024:\n\n2015-06-01\n2016-10-01\n2017-09-01\n2018-02-14\n2018-11-30\n2019-09-01\n2019-10-01\n2020-01-01\n2021-04-01\n2021-10-01\n2023-02-01\nSo we can take this information and request that a specific API version is used:\nWrite a bicep to create a keyvault using this API version Microsoft.KeyVault/vaults@2023-02-01\nAnd we receive an output that includes the newest API version data:\n...\nresource keyVault 'Microsoft.KeyVault/vaults@2023-02-01' \n\n\nEncapsulate separate contexts into separate chats\nThe IBM watsonx Code Assistant extension for Microsoft VS Code is based on a chat-oriented core. When you start a new chat, there is no context until after you have submitted your first prompt. Using the context and persona practices above, you can establish context early and link to specific files in your repo using @&lt;filename&gt;. Your subsequent prompts may then refer to previous outputs, and you can use relative language without needing to re-input your progress or generated content.\nFor example, given the following initial prompt:\nYou are an Ansible engineer. Begin developing a new Ansible role called mq-ocp that deploys IBM MQ to OpenShift 4 with an exposed route. Use the kubernetes.core collection. Use fully qualified collection names. Use parameterization for the kubernetes and MQ resources wherever possible. Format the output as tasks only, suitable for tasks/main.yml.\nOnce you are happy with the generated content, you can follow up with subsequent prompts like the following:\nGenerate defaults/main.yml.\n\nGenerate argSpec.\n\nGenerate meta/main.yml.\n\nGenerate a README.md that includes a synopsis, prerequisites, dependencies, up & running, task explanations, parameter explanations, author, and license information.\n\nGenerate a top-level play called ibm-mq-day0-playbook.yml that runs this role on an inventory called rhel9Servers.\nNOTE: Before you start a new coding session, be sure to start a new chat if you need to start from a clean slate!\n\n\nAlso good to remember\nNeatness counts! Be sure to capitalize the beginning of your sentences, separate sections using commas, and end sentences with periods or question marks. You may even find that good manners get you different results: try using ‚Äúplease‚Äù and see what happens!\nWrite down your good prompts! It‚Äôs good practice to create a simple prompts.md file to keep your prompts in after they are producing good results. You can use them to test updated LLMs as well.",
    "crumbs": [
      "Prompting Guide"
    ]
  },
  {
    "objectID": "index.html#test-your-knowledge-so-far",
    "href": "index.html#test-your-knowledge-so-far",
    "title": "Prompting Guide",
    "section": "Test your knowledge so far",
    "text": "Test your knowledge so far\nHere are some example prompts for you to consider. First, how might you consolidate these two prompts into one, and then how would you improve the final version? What might you need to clarify later?\nUpdate the @deploy.bicep for keyvault to include an event grid system topic which will stream to an azure logic app uri\n\nThe section above has a source and topictype missing. Can you please update this to include those parameters?\nConsider this more complex prompt to build an SSH factory using Rust. What do you notice about it? How specific is it? What would you change?\nYou are a Rust programmer. Generate a Rust struct named SshFactory for managing SSH connections. The struct should have fields for inventory, a flag to forward the SSH agent, and an optional login password. Implement the ConnectionFactory trait with methods get_local_connection and get_connection to create local and remote SSH connections, respectively. Use the ssh2 crate for SSH functionality and ensure the code is thread-safe with appropriate use of Arc and RwLock.\n\n\nFinal Tips for an Optimal Usability Experience\n1 - Although generative AI can be incredibly useful, it can sometimes produce answers that aren‚Äôt exactly what you‚Äôre looking for, or it can give you suggestions that seem off track. If this happens, don‚Äôt hesitate to rewrite or reformulate your request. Your opinion is fundamental in guiding the AI to provide more precise, meaningful and relevant answers.\n2 - Do not hesitate to utilize extensive prompts; in certain scenarios, this approach can enhance the accuracy of prompt suggestions generated by the AI. In summary, a well-crafted prompt is crucial for optimal outcomes.",
    "crumbs": [
      "Prompting Guide"
    ]
  }
]